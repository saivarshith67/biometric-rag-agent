{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:19:08.158018Z",
     "iopub.status.busy": "2025-06-02T10:19:08.157490Z",
     "iopub.status.idle": "2025-06-02T10:19:13.635860Z",
     "shell.execute_reply": "2025-06-02T10:19:13.634170Z",
     "shell.execute_reply.started": "2025-06-02T10:19:08.157979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "directory_path = \"/kaggle/input/suprema-biostar2-documentation\"\n",
    "all_docs = []\n",
    "\n",
    "for file in os.listdir(directory_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:19:13.638157Z",
     "iopub.status.busy": "2025-06-02T10:19:13.637514Z",
     "iopub.status.idle": "2025-06-02T10:19:13.649550Z",
     "shell.execute_reply": "2025-06-02T10:19:13.646367Z",
     "shell.execute_reply.started": "2025-06-02T10:19:13.638122Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'list'>\n60\npage_content='BioStar 2 \nDatabase Table \n \n \nVersion 2.6.0 \n \nVideo Extension \n \n \n \n \n \n \n \n \n \n \n@2018 by Suprema Inc.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2025-06-02T10:01:36+00:00', 'author': 'ynlee', 'moddate': '2025-06-02T10:01:36+00:00', 'source': '/kaggle/input/suprema-biostar2-documentation/documentation-2.pdf', 'total_pages': 19, 'page': 0, 'page_label': '1'}\nBioStar 2 \nDatabase Table \n \n \nVersion 2.6.0 \n \nVideo Extension \n \n \n \n \n \n \n \n \n \n \n@2018 by Suprema Inc.\n"
    }
   ],
   "source": [
    "print(type(all_docs))  # <class 'list'>\n",
    "print(len(all_docs))  # Number of pages or document chunks loaded from all PDFs combined\n",
    "print(all_docs[0])  # Shows the first document object\n",
    "print(all_docs[0].page_content)  # Text content of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:19:13.652169Z",
     "iopub.status.busy": "2025-06-02T10:19:13.651621Z",
     "iopub.status.idle": "2025-06-02T10:19:31.040690Z",
     "shell.execute_reply": "2025-06-02T10:19:31.039482Z",
     "shell.execute_reply.started": "2025-06-02T10:19:13.652130Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "2025-06-02 10:19:21.517173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748859561.550300     398 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748859561.559407     398 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:19:31.043794Z",
     "iopub.status.busy": "2025-06-02T10:19:31.042425Z",
     "iopub.status.idle": "2025-06-02T10:19:52.699618Z",
     "shell.execute_reply": "2025-06-02T10:19:52.695869Z",
     "shell.execute_reply.started": "2025-06-02T10:19:31.043715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Total chunks created: 291\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/tmp/ipykernel_398/3300935356.py:18: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Saved to vector store\n"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "texts = [doc.page_content for doc in all_docs]\n",
    "\n",
    "chunks = []\n",
    "for text in texts:\n",
    "    chunks.extend(text_splitter.split_text(text))\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_texts(chunks, embedding_model)\n",
    "\n",
    "vectorstore.save_local(\"my_faiss_index\")\n",
    "\n",
    "print(\"Saved to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:19:52.703569Z",
     "iopub.status.busy": "2025-06-02T10:19:52.701812Z",
     "iopub.status.idle": "2025-06-02T10:19:52.914324Z",
     "shell.execute_reply": "2025-06-02T10:19:52.912161Z",
     "shell.execute_reply.started": "2025-06-02T10:19:52.703395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:19:52.917566Z",
     "iopub.status.busy": "2025-06-02T10:19:52.916820Z",
     "iopub.status.idle": "2025-06-02T10:19:54.052020Z",
     "shell.execute_reply": "2025-06-02T10:19:54.050937Z",
     "shell.execute_reply.started": "2025-06-02T10:19:52.917528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "OPENROUTER_API_KEY = user_secrets.get_secret(\"OPENROUTER_API_KEY\")\n",
    "OPENROUTER_API_URL = user_secrets.get_secret(\"OPENROUTER_API_URL\")\n",
    "\n",
    "\n",
    "model_id = \"meta-llama/llama-4-maverick:free\"\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_API_URL, model=model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:19:54.053415Z",
     "iopub.status.busy": "2025-06-02T10:19:54.053104Z",
     "iopub.status.idle": "2025-06-02T10:19:55.222407Z",
     "shell.execute_reply": "2025-06-02T10:19:55.221159Z",
     "shell.execute_reply.started": "2025-06-02T10:19:54.053390Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "J'adore la programmation.\n"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful translator. Translate the user sentence to French.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:19:55.223850Z",
     "iopub.status.busy": "2025-06-02T10:19:55.223505Z",
     "iopub.status.idle": "2025-06-02T10:20:07.978272Z",
     "shell.execute_reply": "2025-06-02T10:20:07.976856Z",
     "shell.execute_reply.started": "2025-06-02T10:19:55.223801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1. Search\n2. Exit\n"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": "Enter your choice :  how to add user?\n"
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'how to add user?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_398/2576535359.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1. Search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2. Exit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your choice : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcase\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'how to add user?'"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(\"1. Search\")\n",
    "    print(\"2. Exit\")\n",
    "    choice = int(input(\"Enter your choice : \"))\n",
    "    match choice:\n",
    "        case 1:\n",
    "            query = input(\"Enter your query : \")\n",
    "            result = qa_chain.run(query)\n",
    "            print(result)\n",
    "        case 2:\n",
    "            print(\"Thank you..\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T10:21:05.543366Z",
     "iopub.status.busy": "2025-06-02T10:21:05.542966Z",
     "iopub.status.idle": "2025-06-02T10:21:07.417803Z",
     "shell.execute_reply": "2025-06-02T10:21:07.416100Z",
     "shell.execute_reply.started": "2025-06-02T10:21:05.543331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "To add a user, follow these steps:\n\n1. Press the ESC button and authenticate as an administrator.\n2. Go to \n"
    }
   ],
   "source": [
    "query2 = \"How to add user?\"\n",
    "result = qa_chain.run(query2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-02T10:20:07.981418Z",
     "iopub.status.idle": "2025-06-02T10:20:07.981779Z",
     "shell.execute_reply": "2025-06-02T10:20:07.981648Z",
     "shell.execute_reply.started": "2025-06-02T10:20:07.981633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7572369,
     "sourceId": 12034577,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}